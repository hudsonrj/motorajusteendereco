{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motor de Correspondência - Blocking e Algoritmos de Similaridade\n",
    "\n",
    "Este notebook implementa o motor de correspondência que encontra matches entre endereços normalizados e a Camada Ouro usando estratégias de blocking e algoritmos de similaridade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar configurações\n",
    "%run ./00_configuracao_inicial.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "import re\n",
    "import math\n",
    "\n",
    "# Configurações\n",
    "THRESHOLD_SIMILARIDADE = 0.75  # Threshold mínimo para considerar match\n",
    "THRESHOLD_ALTA_CONFIANCA = 0.90  # Threshold para alta confiança"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UDF para SoundexBR (simplificado)\n",
    "def soundex_br(texto):\n",
    "    \"\"\"Gera código SoundexBR para comparação fonética\"\"\"\n",
    "    if not texto:\n",
    "        return None\n",
    "    \n",
    "    texto = texto.upper().strip()\n",
    "    \n",
    "    # Mapeamento de consoantes para dígitos\n",
    "    mapa = {\n",
    "        'B': '1', 'F': '1', 'P': '1', 'V': '1',\n",
    "        'C': '2', 'G': '2', 'J': '2', 'K': '2', 'Q': '2', 'S': '2', 'X': '2', 'Z': '2',\n",
    "        'D': '3', 'T': '3',\n",
    "        'L': '4',\n",
    "        'M': '5', 'N': '5',\n",
    "        'R': '6'\n",
    "    }\n",
    "    \n",
    "    # Primeira letra\n",
    "    codigo = texto[0] if texto else ''\n",
    "    \n",
    "    # Converter consoantes\n",
    "    for char in texto[1:]:\n",
    "        if char in mapa:\n",
    "            digito = mapa[char]\n",
    "            if codigo[-1] != digito:\n",
    "                codigo += digito\n",
    "    \n",
    "    # Completar com zeros\n",
    "    codigo = codigo[:4].ljust(4, '0')\n",
    "    \n",
    "    return codigo\n",
    "\n",
    "udf_soundex_br = udf(soundex_br, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UDF para Distância de Levenshtein\n",
    "def levenshtein_distance(s1, s2):\n",
    "    \"\"\"Calcula distância de Levenshtein entre duas strings\"\"\"\n",
    "    if not s1 or not s2:\n",
    "        return max(len(s1 or ''), len(s2 or ''))\n",
    "    \n",
    "    s1 = s1.upper()\n",
    "    s2 = s2.upper()\n",
    "    \n",
    "    if s1 == s2:\n",
    "        return 0\n",
    "    \n",
    "    len_s1 = len(s1)\n",
    "    len_s2 = len(s2)\n",
    "    \n",
    "    # Matriz de distâncias\n",
    "    d = [[0] * (len_s2 + 1) for _ in range(len_s1 + 1)]\n",
    "    \n",
    "    # Inicializar primeira linha e coluna\n",
    "    for i in range(len_s1 + 1):\n",
    "        d[i][0] = i\n",
    "    for j in range(len_s2 + 1):\n",
    "        d[0][j] = j\n",
    "    \n",
    "    # Preencher matriz\n",
    "    for i in range(1, len_s1 + 1):\n",
    "        for j in range(1, len_s2 + 1):\n",
    "            if s1[i-1] == s2[j-1]:\n",
    "                cost = 0\n",
    "            else:\n",
    "                cost = 1\n",
    "            \n",
    "            d[i][j] = min(\n",
    "                d[i-1][j] + 1,      # Deletar\n",
    "                d[i][j-1] + 1,      # Inserir\n",
    "                d[i-1][j-1] + cost  # Substituir\n",
    "            )\n",
    "    \n",
    "    return d[len_s1][len_s2]\n",
    "\n",
    "def levenshtein_similarity(s1, s2):\n",
    "    \"\"\"Calcula similaridade baseada em Levenshtein (0-1)\"\"\"\n",
    "    if not s1 or not s2:\n",
    "        return 0.0\n",
    "    \n",
    "    max_len = max(len(s1), len(s2))\n",
    "    if max_len == 0:\n",
    "        return 1.0\n",
    "    \n",
    "    distance = levenshtein_distance(s1, s2)\n",
    "    similarity = 1.0 - (distance / max_len)\n",
    "    \n",
    "    return similarity\n",
    "\n",
    "udf_levenshtein_sim = udf(levenshtein_similarity, DoubleType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UDF para Jaro-Winkler (reutilizado do notebook de clusterização)\n",
    "def jaro_winkler_similarity(s1, s2):\n",
    "    \"\"\"Calcula similaridade Jaro-Winkler\"\"\"\n",
    "    if not s1 or not s2:\n",
    "        return 0.0\n",
    "    \n",
    "    s1 = s1.upper().strip()\n",
    "    s2 = s2.upper().strip()\n",
    "    \n",
    "    if s1 == s2:\n",
    "        return 1.0\n",
    "    \n",
    "    len_s1 = len(s1)\n",
    "    len_s2 = len(s2)\n",
    "    match_window = max(len_s1, len_s2) // 2 - 1\n",
    "    if match_window < 0:\n",
    "        match_window = 0\n",
    "    \n",
    "    s1_matches = [False] * len_s1\n",
    "    s2_matches = [False] * len_s2\n",
    "    matches = 0\n",
    "    transpositions = 0\n",
    "    \n",
    "    for i in range(len_s1):\n",
    "        start = max(0, i - match_window)\n",
    "        end = min(i + match_window + 1, len_s2)\n",
    "        \n",
    "        for j in range(start, end):\n",
    "            if s2_matches[j] or s1[i] != s2[j]:\n",
    "                continue\n",
    "            s1_matches[i] = True\n",
    "            s2_matches[j] = True\n",
    "            matches += 1\n",
    "            break\n",
    "    \n",
    "    if matches == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    k = 0\n",
    "    for i in range(len_s1):\n",
    "        if not s1_matches[i]:\n",
    "            continue\n",
    "        while not s2_matches[k]:\n",
    "            k += 1\n",
    "        if s1[i] != s2[k]:\n",
    "            transpositions += 1\n",
    "        k += 1\n",
    "    \n",
    "    jaro = (matches / len_s1 + matches / len_s2 + (matches - transpositions / 2) / matches) / 3.0\n",
    "    \n",
    "    prefix = 0\n",
    "    for i in range(min(len(s1), len(s2), 4)):\n",
    "        if s1[i] == s2[i]:\n",
    "            prefix += 1\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    winkler = jaro + (0.1 * prefix * (1 - jaro))\n",
    "    \n",
    "    return min(1.0, winkler)\n",
    "\n",
    "udf_jaro_winkler = udf(jaro_winkler_similarity, DoubleType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função de blocking: Filtro Rígido (UF + Cidade)\n",
    "def aplicar_blocking_rigido(df_enderecos, df_camada_ouro):\n",
    "    \"\"\"\n",
    "    Aplica blocking rígido: filtra apenas endereços da mesma UF e Cidade\n",
    "    \n",
    "    Args:\n",
    "        df_enderecos: DataFrame com endereços normalizados\n",
    "        df_camada_ouro: DataFrame com Camada Ouro\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame com candidatos após blocking rígido\n",
    "    \"\"\"\n",
    "    df_candidatos = df_enderecos.alias(\"e\").join(\n",
    "        df_camada_ouro.alias(\"o\"),\n",
    "        (col(\"e.uf\") == col(\"o.uf\")) & (col(\"e.cidade\") == col(\"o.cidade\")),\n",
    "        \"inner\"\n",
    "    )\n",
    "    \n",
    "    return df_candidatos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função de blocking: Filtro Flexível (Fonética do Bairro)\n",
    "def aplicar_blocking_flexivel(df_candidatos_rigido):\n",
    "    \"\"\"\n",
    "    Aplica blocking flexível usando SoundexBR do bairro\n",
    "    \n",
    "    Args:\n",
    "        df_candidatos_rigido: DataFrame após blocking rígido\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame com candidatos após blocking flexível\n",
    "    \"\"\"\n",
    "    df_candidatos_flex = df_candidatos_rigido \\\n",
    "        .withColumn(\"soundex_bairro_e\", udf_soundex_br(col(\"e.bairro_norm\"))) \\\n",
    "        .withColumn(\"soundex_bairro_o\", udf_soundex_br(col(\"o.bairro\"))) \\\n",
    "        .filter(\n",
    "            (col(\"soundex_bairro_e\") == col(\"soundex_bairro_o\")) |\n",
    "            (col(\"e.bairro_norm\").isNull()) |\n",
    "            (col(\"o.bairro\").isNull())\n",
    "        )\n",
    "    \n",
    "    return df_candidatos_flex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para calcular scores de similaridade\n",
    "def calcular_scores_similaridade(df_candidatos):\n",
    "    \"\"\"\n",
    "    Calcula múltiplos scores de similaridade para cada candidato\n",
    "    \n",
    "    Args:\n",
    "        df_candidatos: DataFrame com candidatos após blocking\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame com scores de similaridade\n",
    "    \"\"\"\n",
    "    df_com_scores = df_candidatos \\\n",
    "        .withColumn(\"sim_jaro_winkler\", \n",
    "            udf_jaro_winkler(col(\"e.nome_logradouro_norm\"), col(\"o.nome_logradouro\"))) \\\n",
    "        .withColumn(\"sim_levenshtein\", \n",
    "            udf_levenshtein_sim(col(\"e.nome_logradouro_norm\"), col(\"o.nome_logradouro\"))) \\\n",
    "        .withColumn(\"match_numero\", \n",
    "            when(col(\"e.numero\") == col(\"o.numero\"), 1.0).otherwise(0.0)) \\\n",
    "        .withColumn(\"match_tipo_log\", \n",
    "            when(col(\"e.tipo_logradouro_norm\") == col(\"o.tipo_logradouro\"), 1.0).otherwise(0.0))\n",
    "    \n",
    "    # Score combinado (pesos configuráveis)\n",
    "    df_com_scores = df_com_scores \\\n",
    "        .withColumn(\"score_final\", \n",
    "            (col(\"sim_jaro_winkler\") * 0.4 + \n",
    "             col(\"sim_levenshtein\") * 0.3 + \n",
    "             col(\"match_numero\") * 0.2 + \n",
    "             col(\"match_tipo_log\") * 0.1)\n",
    "        ) \\\n",
    "        .withColumn(\"confianca\", \n",
    "            when(col(\"score_final\") >= THRESHOLD_ALTA_CONFIANCA, \"ALTA\")\n",
    "            .when(col(\"score_final\") >= THRESHOLD_SIMILARIDADE, \"MEDIA\")\n",
    "            .otherwise(\"BAIXA\")\n",
    "        )\n",
    "    \n",
    "    return df_com_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função principal do motor de correspondência\n",
    "def executar_motor_correspondencia(df_enderecos_normalizados):\n",
    "    \"\"\"\n",
    "    Executa motor de correspondência completo\n",
    "    \n",
    "    Args:\n",
    "        df_enderecos_normalizados: DataFrame com endereços normalizados\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame com matches encontrados\n",
    "    \"\"\"\n",
    "    print(\"1. Carregando Camada Ouro...\")\n",
    "    df_camada_ouro = read_delta_table(PATH_CAMADA_OURO)\n",
    "    print(f\"   Registros na Camada Ouro: {df_camada_ouro.count()}\")\n",
    "    \n",
    "    print(\"2. Aplicando blocking rígido (UF + Cidade)...\")\n",
    "    df_candidatos_rigido = aplicar_blocking_rigido(df_enderecos_normalizados, df_camada_ouro)\n",
    "    print(f\"   Candidatos após blocking rígido: {df_candidatos_rigido.count()}\")\n",
    "    \n",
    "    print(\"3. Aplicando blocking flexível (SoundexBR bairro)...\")\n",
    "    df_candidatos_flex = aplicar_blocking_flexivel(df_candidatos_rigido)\n",
    "    print(f\"   Candidatos após blocking flexível: {df_candidatos_flex.count()}\")\n",
    "    \n",
    "    print(\"4. Calculando scores de similaridade...\")\n",
    "    df_com_scores = calcular_scores_similaridade(df_candidatos_flex)\n",
    "    \n",
    "    print(\"5. Filtrando matches acima do threshold...\")\n",
    "    df_matches = df_com_scores \\\n",
    "        .filter(col(\"score_final\") >= THRESHOLD_SIMILARIDADE) \\\n",
    "        .select(\n",
    "            col(\"e.id\").alias(\"id_endereco_input\"),\n",
    "            col(\"e.endereco_livre\"),\n",
    "            col(\"e.endereco_normalizado\"),\n",
    "            col(\"o.uid\").alias(\"uid_camada_ouro\"),\n",
    "            col(\"o.endereco_normalizado\").alias(\"endereco_camada_ouro\"),\n",
    "            col(\"sim_jaro_winkler\"),\n",
    "            col(\"sim_levenshtein\"),\n",
    "            col(\"score_final\"),\n",
    "            col(\"confianca\"),\n",
    "            col(\"o.latitude\"),\n",
    "            col(\"o.longitude\"),\n",
    "            col(\"o.score_confianca\").alias(\"score_confianca_ouro\")\n",
    "        )\n",
    "    \n",
    "    # Para cada endereço de entrada, manter apenas o melhor match\n",
    "    from pyspark.sql.window import Window\n",
    "    window_spec = Window.partitionBy(\"id_endereco_input\").orderBy(desc(\"score_final\"))\n",
    "    \n",
    "    df_matches_final = df_matches \\\n",
    "        .withColumn(\"rank\", row_number().over(window_spec)) \\\n",
    "        .filter(col(\"rank\") == 1) \\\n",
    "        .drop(\"rank\") \\\n",
    "        .withColumn(\"match_em\", current_timestamp())\n",
    "    \n",
    "    print(f\"   Matches encontrados: {df_matches_final.count()}\")\n",
    "    \n",
    "    return df_matches_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo de uso\n",
    "# df_enderecos_normalizados = read_delta_table(PATH_ENDERECOS_NORMALIZADOS)\n",
    "# df_matches = executar_motor_correspondencia(df_enderecos_normalizados)\n",
    "\n",
    "# Visualizar matches\n",
    "# df_matches.show(20, truncate=False)\n",
    "\n",
    "# Estatísticas\n",
    "# df_matches.groupBy(\"confianca\").agg(\n",
    "#     count(\"*\").alias(\"quantidade\")\n",
    "# ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar matches\n",
    "# save_delta_table(df_matches, PATH_MATCHES, mode=\"append\", partition_by=[\"confianca\"])\n",
    "\n",
    "print(\"Motor de correspondência executado com sucesso!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
