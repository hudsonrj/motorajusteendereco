{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criação da Camada Ouro - Deduplicação e Cruzamento\n",
    "\n",
    "Este notebook cria a Camada Ouro (Golden Record) através da deduplicação e cruzamento de dados de múltiplas fontes (DNE, CNEFE, OSM)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar configurações\n",
    "%run ./00_configuracao_inicial.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window\n",
    "import hashlib\n",
    "\n",
    "# Schema esperado para dados de fontes (DNE, CNEFE, OSM)\n",
    "schema_fonte = StructType([\n",
    "    StructField(\"id_fonte\", StringType(), True),\n",
    "    StructField(\"fonte\", StringType(), True),  # DNE, CNEFE, OSM\n",
    "    StructField(\"tipo_logradouro\", StringType(), True),\n",
    "    StructField(\"nome_logradouro\", StringType(), True),\n",
    "    StructField(\"numero\", StringType(), True),\n",
    "    StructField(\"bairro\", StringType(), True),\n",
    "    StructField(\"cidade\", StringType(), True),\n",
    "    StructField(\"uf\", StringType(), True),\n",
    "    StructField(\"cep\", StringType(), True),\n",
    "    StructField(\"latitude\", DoubleType(), True),\n",
    "    StructField(\"longitude\", DoubleType(), True),\n",
    "    StructField(\"confiabilidade\", DoubleType(), True),  # Score de confiabilidade da fonte\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UDF para gerar hash do endereço (usado para deduplicação)\n",
    "def gerar_hash_endereco(tipo_log, nome_log, numero, bairro, cidade, uf):\n",
    "    \"\"\"Gera hash MD5 do endereço para identificação de duplicatas\"\"\"\n",
    "    endereco_completo = f\"{tipo_log}|{nome_log}|{numero}|{bairro}|{cidade}|{uf}\"\n",
    "    endereco_normalizado = endereco_completo.upper().strip().replace(\" \", \"\")\n",
    "    return hashlib.md5(endereco_normalizado.encode('utf-8')).hexdigest()\n",
    "\n",
    "udf_gerar_hash = udf(gerar_hash_endereco, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para carregar e normalizar dados de uma fonte\n",
    "def carregar_fonte(path_fonte, nome_fonte):\n",
    "    \"\"\"\n",
    "    Carrega dados de uma fonte e adiciona metadados\n",
    "    \n",
    "    Args:\n",
    "        path_fonte: Caminho no MinIO para os dados da fonte\n",
    "        nome_fonte: Nome da fonte (DNE, CNEFE, OSM)\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame com dados da fonte\n",
    "    \"\"\"\n",
    "    df_fonte = read_delta_table(path_fonte) \\\n",
    "        .withColumn(\"fonte\", lit(nome_fonte)) \\\n",
    "        .withColumn(\"hash_endereco\", \n",
    "            udf_gerar_hash(\n",
    "                col(\"tipo_logradouro\"),\n",
    "                col(\"nome_logradouro\"),\n",
    "                col(\"numero\"),\n",
    "                col(\"bairro\"),\n",
    "                col(\"cidade\"),\n",
    "                col(\"uf\")\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    return df_fonte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para unificar todas as fontes\n",
    "def unificar_fontes():\n",
    "    \"\"\"\n",
    "    Carrega e unifica dados de todas as fontes (DNE, CNEFE, OSM)\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame unificado com todas as fontes\n",
    "    \"\"\"\n",
    "    # Carregar cada fonte\n",
    "    df_dne = carregar_fonte(PATH_DNE, \"DNE\")\n",
    "    df_cnefe = carregar_fonte(PATH_CNEFE, \"CNEFE\")\n",
    "    df_osm = carregar_fonte(PATH_OSM, \"OSM\")\n",
    "    \n",
    "    # Unificar todas as fontes\n",
    "    df_unificado = df_dne.unionByName(df_cnefe, allowMissingColumns=True) \\\n",
    "                        .unionByName(df_osm, allowMissingColumns=True)\n",
    "    \n",
    "    return df_unificado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para deduplicar por hash\n",
    "def deduplicar_por_hash(df_unificado):\n",
    "    \"\"\"\n",
    "    Remove duplicatas exatas usando hash do endereço\n",
    "    Mantém o registro com maior confiabilidade\n",
    "    \n",
    "    Args:\n",
    "        df_unificado: DataFrame com dados de todas as fontes\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame deduplicado\n",
    "    \"\"\"\n",
    "    window_spec = Window.partitionBy(\"hash_endereco\").orderBy(desc(\"confiabilidade\"), desc(\"fonte\"))\n",
    "    \n",
    "    df_deduplicado = df_unificado \\\n",
    "        .withColumn(\"rank\", row_number().over(window_spec)) \\\n",
    "        .filter(col(\"rank\") == 1) \\\n",
    "        .drop(\"rank\")\n",
    "    \n",
    "    return df_deduplicado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para criar registro canônico (Golden Record)\n",
    "def criar_registro_canonico(df_deduplicado):\n",
    "    \"\"\"\n",
    "    Cria registro canônico agregando informações de múltiplas fontes\n",
    "    quando há correspondência geográfica\n",
    "    \n",
    "    Args:\n",
    "        df_deduplicado: DataFrame deduplicado\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame com registros canônicos\n",
    "    \"\"\"\n",
    "    # Agrupar por hash e agregar informações\n",
    "    df_canonico = df_deduplicado \\\n",
    "        .groupBy(\"hash_endereco\", \"uf\", \"cidade\", \"tipo_logradouro\", \"nome_logradouro\", \"numero\", \"bairro\") \\\n",
    "        .agg(\n",
    "            collect_list(\"fonte\").alias(\"fontes\"),\n",
    "            avg(\"latitude\").alias(\"latitude\"),\n",
    "            avg(\"longitude\").alias(\"longitude\"),\n",
    "            max(\"confiabilidade\").alias(\"confiabilidade_max\"),\n",
    "            count(\"*\").alias(\"num_fontes\"),\n",
    "            first(\"cep\").alias(\"cep\"),\n",
    "            first(\"id_fonte\").alias(\"id_principal\")\n",
    "        ) \\\n",
    "        .withColumn(\"uid\", \n",
    "            concat(\n",
    "                lit(\"UID_\"),\n",
    "                col(\"hash_endereco\")\n",
    "            )\n",
    "        ) \\\n",
    "        .withColumn(\"score_confianca\", \n",
    "            when(col(\"num_fontes\") >= 3, 1.0)  # 3+ fontes concordam\n",
    "            .when(col(\"num_fontes\") == 2, 0.8)  # 2 fontes concordam\n",
    "            .otherwise(0.6)  # 1 fonte apenas\n",
    "        ) \\\n",
    "        .withColumn(\"criado_em\", current_timestamp()) \\\n",
    "        .select(\n",
    "            col(\"uid\"),\n",
    "            col(\"hash_endereco\"),\n",
    "            col(\"uf\"),\n",
    "            col(\"cidade\"),\n",
    "            col(\"tipo_logradouro\"),\n",
    "            col(\"nome_logradouro\"),\n",
    "            col(\"numero\"),\n",
    "            col(\"bairro\"),\n",
    "            col(\"cep\"),\n",
    "            col(\"latitude\"),\n",
    "            col(\"longitude\"),\n",
    "            col(\"fontes\"),\n",
    "            col(\"num_fontes\"),\n",
    "            col(\"score_confianca\"),\n",
    "            col(\"confiabilidade_max\"),\n",
    "            col(\"criado_em\")\n",
    "        )\n",
    "    \n",
    "    return df_canonico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline completo para criar Camada Ouro\n",
    "def criar_camada_ouro():\n",
    "    \"\"\"\n",
    "    Pipeline completo para criar a Camada Ouro\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame com Camada Ouro\n",
    "    \"\"\"\n",
    "    print(\"1. Unificando fontes...\")\n",
    "    df_unificado = unificar_fontes()\n",
    "    print(f\"   Total de registros unificados: {df_unificado.count()}\")\n",
    "    \n",
    "    print(\"2. Deduplicando por hash...\")\n",
    "    df_deduplicado = deduplicar_por_hash(df_unificado)\n",
    "    print(f\"   Total após deduplicação: {df_deduplicado.count()}\")\n",
    "    \n",
    "    print(\"3. Criando registros canônicos...\")\n",
    "    df_camada_ouro = criar_registro_canonico(df_deduplicado)\n",
    "    print(f\"   Total de registros canônicos: {df_camada_ouro.count()}\")\n",
    "    \n",
    "    return df_camada_ouro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executar pipeline\n",
    "# df_camada_ouro = criar_camada_ouro()\n",
    "\n",
    "# Visualizar amostra\n",
    "# df_camada_ouro.show(10, truncate=False)\n",
    "\n",
    "# Estatísticas\n",
    "# df_camada_ouro.agg(\n",
    "#     count(\"*\").alias(\"total_registros\"),\n",
    "#     avg(\"num_fontes\").alias(\"media_fontes\"),\n",
    "#     avg(\"score_confianca\").alias(\"score_confianca_medio\")\n",
    "# ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar Camada Ouro\n",
    "# save_delta_table(df_camada_ouro, PATH_CAMADA_OURO, mode=\"overwrite\", partition_by=[\"uf\", \"cidade\"])\n",
    "\n",
    "print(\"Camada Ouro criada com sucesso!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
