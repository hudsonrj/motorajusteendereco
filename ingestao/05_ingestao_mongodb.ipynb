{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ingestão de Dados - MongoDB\n",
    "\n",
    "Este notebook realiza a ingestão de dados de um banco de dados MongoDB para o MinIO usando DeltaLake.\n",
    "\n",
    "## Configuração\n",
    "\n",
    "Configure as variáveis abaixo antes de executar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar configurações base\n",
    "%run ../00_configuracao_inicial.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CONFIGURAÇÕES DE CONEXÃO MONGODB\n",
    "# ============================================\n",
    "import os\n",
    "\n",
    "# Configurações de conexão MongoDB\n",
    "MONGODB_HOST = os.getenv('MONGODB_HOST', 'localhost')\n",
    "MONGODB_PORT = os.getenv('MONGODB_PORT', '27017')\n",
    "MONGODB_DATABASE = os.getenv('MONGODB_DATABASE', 'admin')\n",
    "MONGODB_USER = os.getenv('MONGODB_USER', 'admin')\n",
    "MONGODB_PASSWORD = os.getenv('MONGODB_PASSWORD', 'senha')\n",
    "MONGODB_AUTH_DB = os.getenv('MONGODB_AUTH_DB', 'admin')  # Database de autenticação\n",
    "\n",
    "# Configurações de leitura\n",
    "MONGODB_COLLECTION = os.getenv('MONGODB_COLLECTION', 'nome_colecao')\n",
    "\n",
    "# Configurações de destino no MinIO\n",
    "DESTINO_BRONZE = f\"{PATH_BRONZE}/mongodb/{MONGODB_DATABASE.lower()}/{MONGODB_COLLECTION.lower()}\"\n",
    "\n",
    "print(\"Configurações MongoDB:\")\n",
    "print(f\"Host: {MONGODB_HOST}\")\n",
    "print(f\"Port: {MONGODB_PORT}\")\n",
    "print(f\"Database: {MONGODB_DATABASE}\")\n",
    "print(f\"Collection: {MONGODB_COLLECTION}\")\n",
    "print(f\"Destino: {DESTINO_BRONZE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalar MongoDB Spark Connector (executar apenas uma vez)\n",
    "# !pip install pymongo\n",
    "\n",
    "# Adicionar MongoDB Spark Connector ao Spark\n",
    "# Baixar mongo-spark-connector_2.12-XX.X.X.jar\n",
    "# Ou usar: spark.jars.packages com coordenadas Maven: org.mongodb.spark:mongo-spark-connector_2.12:XX.X.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "import json\n",
    "\n",
    "# URI de conexão MongoDB\n",
    "# Formato: mongodb://[username:password@]host[:port][/[database][?options]]\n",
    "if MONGODB_USER and MONGODB_PASSWORD:\n",
    "    mongodb_uri = f\"mongodb://{MONGODB_USER}:{MONGODB_PASSWORD}@{MONGODB_HOST}:{MONGODB_PORT}/{MONGODB_DATABASE}?authSource={MONGODB_AUTH_DB}\"\n",
    "else:\n",
    "    mongodb_uri = f\"mongodb://{MONGODB_HOST}:{MONGODB_PORT}/{MONGODB_DATABASE}\"\n",
    "\n",
    "print(f\"MongoDB URI: mongodb://***:***@{MONGODB_HOST}:{MONGODB_PORT}/{MONGODB_DATABASE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para ler dados do MongoDB\n",
    "def ler_mongodb_collection(database, collection, query=None, pipeline=None, read_preference=\"primary\"):\n",
    "    \"\"\"\n",
    "    Lê dados de uma coleção MongoDB\n",
    "    \n",
    "    Args:\n",
    "        database: Nome do banco de dados\n",
    "        collection: Nome da coleção\n",
    "        query: Query MongoDB em formato JSON (opcional)\n",
    "        pipeline: Pipeline de agregação MongoDB (opcional, substitui query)\n",
    "        read_preference: Preferência de leitura (primary, secondary, etc)\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame do Spark\n",
    "    \"\"\"\n",
    "    reader = spark.read.format(\"mongo\") \\\n",
    "        .option(\"uri\", mongodb_uri) \\\n",
    "        .option(\"database\", database) \\\n",
    "        .option(\"collection\", collection) \\\n",
    "        .option(\"readPreference.name\", read_preference)\n",
    "    \n",
    "    # Adicionar query se fornecida\n",
    "    if pipeline:\n",
    "        # Pipeline de agregação\n",
    "        reader = reader.option(\"pipeline\", pipeline)\n",
    "    elif query:\n",
    "        # Query simples\n",
    "        reader = reader.option(\"query\", query)\n",
    "    \n",
    "    df = reader.load()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo 1: Leitura simples de coleção\n",
    "print(\"Exemplo 1: Leitura simples\")\n",
    "df_mongodb = ler_mongodb_collection(\n",
    "    database=MONGODB_DATABASE,\n",
    "    collection=MONGODB_COLLECTION\n",
    ")\n",
    "\n",
    "print(f\"Total de registros: {df_mongodb.count()}\")\n",
    "df_mongodb.printSchema()\n",
    "df_mongodb.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo 2: Leitura com query MongoDB\n",
    "print(\"Exemplo 2: Leitura com query\")\n",
    "query_mongodb = {\n",
    "    \"status\": \"ativo\",\n",
    "    \"created_at\": {\"$gte\": \"2024-01-01\"}\n",
    "}\n",
    "\n",
    "# df_mongodb_query = ler_mongodb_collection(\n",
    "#     database=MONGODB_DATABASE,\n",
    "#     collection=MONGODB_COLLECTION,\n",
    "#     query=json.dumps(query_mongodb)\n",
    "# )\n",
    "# df_mongodb_query.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo 3: Leitura com pipeline de agregação\n",
    "print(\"Exemplo 3: Leitura com pipeline de agregação\")\n",
    "pipeline_agregacao = [\n",
    "    {\"$match\": {\"status\": \"ativo\"}},\n",
    "    {\"$project\": {\"nome\": 1, \"email\": 1, \"created_at\": 1}},\n",
    "    {\"$sort\": {\"created_at\": -1}},\n",
    "    {\"$limit\": 1000}\n",
    "]\n",
    "\n",
    "# df_mongodb_pipeline = ler_mongodb_collection(\n",
    "#     database=MONGODB_DATABASE,\n",
    "#     collection=MONGODB_COLLECTION,\n",
    "#     pipeline=json.dumps(pipeline_agregacao)\n",
    "# )\n",
    "# df_mongodb_pipeline.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processar campos aninhados do MongoDB (se necessário)\n",
    "# MongoDB armazena documentos JSON, que podem ter estruturas aninhadas\n",
    "def processar_documentos_mongodb(df):\n",
    "    \"\"\"\n",
    "    Processa documentos MongoDB, extraindo campos aninhados\n",
    "    \"\"\"\n",
    "    # Exemplo: extrair campos de um objeto aninhado\n",
    "    # df_processado = df.withColumn(\"campo_extraido\", col(\"documento.campo_aninhado\"))\n",
    "    \n",
    "    # Converter _id ObjectId para string (se necessário)\n",
    "    df_processado = df.withColumn(\"_id_str\", col(\"_id\").cast(StringType()))\n",
    "    \n",
    "    return df_processado\n",
    "\n",
    "# Aplicar processamento\n",
    "df_mongodb_processado = processar_documentos_mongodb(df_mongodb)\n",
    "df_mongodb_processado.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicionar metadados de ingestão\n",
    "df_ingestao = df_mongodb_processado \\\n",
    "    .withColumn(\"fonte\", lit(\"MONGODB\")) \\\n",
    "    .withColumn(\"database_origem\", lit(MONGODB_DATABASE)) \\\n",
    "    .withColumn(\"collection_origem\", lit(MONGODB_COLLECTION)) \\\n",
    "    .withColumn(\"ingestao_em\", current_timestamp()) \\\n",
    "    .withColumn(\"particao_data\", date_format(current_date(), \"yyyy-MM-dd\"))\n",
    "\n",
    "print(\"Metadados adicionados:\")\n",
    "df_ingestao.select(\"fonte\", \"database_origem\", \"collection_origem\", \"ingestao_em\").show(1, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar no MinIO como Delta Table\n",
    "print(f\"Salvando dados em: {DESTINO_BRONZE}\")\n",
    "\n",
    "# save_delta_table(\n",
    "#     df_ingestao,\n",
    "#     DESTINO_BRONZE,\n",
    "#     mode=\"overwrite\",  # ou \"append\" para incrementais\n",
    "#     partition_by=[\"particao_data\"]  # Particionar por data\n",
    "# )\n",
    "\n",
    "print(\"Ingestão concluída com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar dados salvos\n",
    "# df_verificacao = read_delta_table(DESTINO_BRONZE)\n",
    "# print(f\"Registros salvos: {df_verificacao.count()}\")\n",
    "# df_verificacao.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingestão Incremental\n",
    "\n",
    "Para ingestões incrementais baseadas em timestamp ou ObjectId:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para ingestão incremental usando timestamp\n",
    "def ingestao_incremental_mongodb_timestamp(database, collection, coluna_timestamp=\"updated_at\", ultima_execucao=None):\n",
    "    \"\"\"\n",
    "    Realiza ingestão incremental de dados MongoDB usando timestamp\n",
    "    \n",
    "    Args:\n",
    "        database: Nome do banco\n",
    "        collection: Nome da coleção\n",
    "        coluna_timestamp: Nome do campo de timestamp\n",
    "        ultima_execucao: Timestamp da última execução (formato ISO ou datetime)\n",
    "    \"\"\"\n",
    "    if ultima_execucao:\n",
    "        query = {\n",
    "            coluna_timestamp: {\"$gt\": ultima_execucao}\n",
    "        }\n",
    "    else:\n",
    "        # Primeira execução: pegar últimos 7 dias\n",
    "        from datetime import datetime, timedelta\n",
    "        data_limite = datetime.now() - timedelta(days=7)\n",
    "        query = {\n",
    "            coluna_timestamp: {\"$gte\": data_limite}\n",
    "        }\n",
    "    \n",
    "    df_incremental = ler_mongodb_collection(\n",
    "        database=database,\n",
    "        collection=collection,\n",
    "        query=json.dumps(query)\n",
    "    )\n",
    "    \n",
    "    return df_incremental\n",
    "\n",
    "# Função para ingestão incremental usando ObjectId\n",
    "def ingestao_incremental_mongodb_objectid(database, collection, ultimo_objectid=None):\n",
    "    \"\"\"\n",
    "    Realiza ingestão incremental usando ObjectId (mais eficiente)\n",
    "    ObjectId contém timestamp, então pode ser usado para ordenação\n",
    "    \"\"\"\n",
    "    if ultimo_objectid:\n",
    "        from bson import ObjectId\n",
    "        query = {\n",
    "            \"_id\": {\"$gt\": ObjectId(ultimo_objectid)}\n",
    "        }\n",
    "    else:\n",
    "        # Primeira execução: pegar últimos 7 dias\n",
    "        from datetime import datetime, timedelta\n",
    "        from bson import ObjectId\n",
    "        data_limite = datetime.now() - timedelta(days=7)\n",
    "        objectid_limite = ObjectId.from_datetime(data_limite)\n",
    "        query = {\n",
    "            \"_id\": {\"$gte\": objectid_limite}\n",
    "        }\n",
    "    \n",
    "    pipeline = [\n",
    "        {\"$match\": query},\n",
    "        {\"$sort\": {\"_id\": 1}}\n",
    "    ]\n",
    "    \n",
    "    df_incremental = ler_mongodb_collection(\n",
    "        database=database,\n",
    "        collection=collection,\n",
    "        pipeline=json.dumps(pipeline)\n",
    "    )\n",
    "    \n",
    "    return df_incremental\n",
    "\n",
    "# Exemplo de uso\n",
    "# df_incremental = ingestao_incremental_mongodb_timestamp(\n",
    "#     database=MONGODB_DATABASE,\n",
    "#     collection=MONGODB_COLLECTION,\n",
    "#     ultima_execucao=\"2024-01-01T00:00:00Z\"\n",
    "# )\n",
    "# \n",
    "# # Salvar em modo append\n",
    "# save_delta_table(df_incremental, DESTINO_BRONZE, mode=\"append\", partition_by=[\"particao_data\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
