{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ingestão de Dados - Oracle Database\n",
    "\n",
    "Este notebook realiza a ingestão de dados de um banco de dados Oracle para o MinIO usando DeltaLake.\n",
    "\n",
    "## Configuração\n",
    "\n",
    "Configure as variáveis abaixo antes de executar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar configurações base\n",
    "%run ../00_configuracao_inicial.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CONFIGURAÇÕES DE CONEXÃO ORACLE\n",
    "# ============================================\n",
    "import os\n",
    "\n",
    "# Configurações de conexão Oracle\n",
    "ORACLE_HOST = os.getenv('ORACLE_HOST', 'localhost')\n",
    "ORACLE_PORT = os.getenv('ORACLE_PORT', '1521')\n",
    "ORACLE_SERVICE_NAME = os.getenv('ORACLE_SERVICE_NAME', 'ORCL')\n",
    "ORACLE_USER = os.getenv('ORACLE_USER', 'usuario')\n",
    "ORACLE_PASSWORD = os.getenv('ORACLE_PASSWORD', 'senha')\n",
    "\n",
    "# Configurações de leitura\n",
    "ORACLE_SCHEMA = os.getenv('ORACLE_SCHEMA', 'SCHEMA_NAME')\n",
    "ORACLE_TABLE = os.getenv('ORACLE_TABLE', 'NOME_TABELA')\n",
    "\n",
    "# Configurações de destino no MinIO\n",
    "DESTINO_BRONZE = f\"{PATH_BRONZE}/oracle/{ORACLE_SCHEMA.lower()}/{ORACLE_TABLE.lower()}\"\n",
    "\n",
    "print(\"Configurações Oracle:\")\n",
    "print(f\"Host: {ORACLE_HOST}\")\n",
    "print(f\"Port: {ORACLE_PORT}\")\n",
    "print(f\"Service Name: {ORACLE_SERVICE_NAME}\")\n",
    "print(f\"Schema: {ORACLE_SCHEMA}\")\n",
    "print(f\"Table: {ORACLE_TABLE}\")\n",
    "print(f\"Destino: {DESTINO_BRONZE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalar driver JDBC Oracle (executar apenas uma vez)\n",
    "# !pip install cx_Oracle\n",
    "\n",
    "# Adicionar driver JDBC Oracle ao Spark\n",
    "# Baixar ojdbc8.jar e colocar no classpath do Spark\n",
    "# Ou usar: spark.jars.packages com coordenadas Maven"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "# URL de conexão JDBC Oracle\n",
    "jdbc_url = f\"jdbc:oracle:thin:@{ORACLE_HOST}:{ORACLE_PORT}/{ORACLE_SERVICE_NAME}\"\n",
    "\n",
    "# Propriedades de conexão\n",
    "connection_properties = {\n",
    "    \"user\": ORACLE_USER,\n",
    "    \"password\": ORACLE_PASSWORD,\n",
    "    \"driver\": \"oracle.jdbc.OracleDriver\"\n",
    "}\n",
    "\n",
    "print(f\"JDBC URL: {jdbc_url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para ler dados do Oracle\n",
    "def ler_oracle_table(table_name, schema=None, query=None, partition_column=None, num_partitions=None, lower_bound=None, upper_bound=None):\n",
    "    \"\"\"\n",
    "    Lê dados de uma tabela Oracle\n",
    "    \n",
    "    Args:\n",
    "        table_name: Nome da tabela\n",
    "        schema: Schema (opcional)\n",
    "        query: Query SQL customizada (opcional, substitui table_name)\n",
    "        partition_column: Coluna para particionamento paralelo (opcional)\n",
    "        num_partitions: Número de partições (opcional)\n",
    "        lower_bound: Valor mínimo para particionamento (opcional)\n",
    "        upper_bound: Valor máximo para particionamento (opcional)\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame do Spark\n",
    "    \"\"\"\n",
    "    if query:\n",
    "        # Usar query customizada (subquery)\n",
    "        table_or_query = f\"({query}) oracle_table\"\n",
    "    elif schema:\n",
    "        table_or_query = f\"{schema}.{table_name}\"\n",
    "    else:\n",
    "        table_or_query = table_name\n",
    "    \n",
    "    reader = spark.read.format(\"jdbc\") \\\n",
    "        .option(\"url\", jdbc_url) \\\n",
    "        .option(\"dbtable\", table_or_query) \\\n",
    "        .option(\"user\", ORACLE_USER) \\\n",
    "        .option(\"password\", ORACLE_PASSWORD) \\\n",
    "        .option(\"driver\", \"oracle.jdbc.OracleDriver\")\n",
    "    \n",
    "    # Adicionar opções de particionamento se fornecidas\n",
    "    if partition_column and num_partitions:\n",
    "        reader = reader.option(\"partitionColumn\", partition_column) \\\n",
    "                      .option(\"numPartitions\", num_partitions)\n",
    "        if lower_bound is not None and upper_bound is not None:\n",
    "            reader = reader.option(\"lowerBound\", lower_bound) \\\n",
    "                          .option(\"upperBound\", upper_bound)\n",
    "    \n",
    "    df = reader.load()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo 1: Leitura simples de tabela\n",
    "print(\"Exemplo 1: Leitura simples\")\n",
    "df_oracle = ler_oracle_table(\n",
    "    table_name=ORACLE_TABLE,\n",
    "    schema=ORACLE_SCHEMA\n",
    ")\n",
    "\n",
    "print(f\"Total de registros: {df_oracle.count()}\")\n",
    "df_oracle.printSchema()\n",
    "df_oracle.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo 2: Leitura com query customizada\n",
    "print(\"Exemplo 2: Leitura com query customizada\")\n",
    "query_customizada = f\"\"\"\n",
    "    SELECT \n",
    "        coluna1,\n",
    "        coluna2,\n",
    "        coluna3,\n",
    "        TO_CHAR(data_atualizacao, 'YYYY-MM-DD HH24:MI:SS') as data_atualizacao_str\n",
    "    FROM {ORACLE_SCHEMA}.{ORACLE_TABLE}\n",
    "    WHERE data_atualizacao >= SYSDATE - 30\n",
    "    ORDER BY data_atualizacao DESC\n",
    "\"\"\"\n",
    "\n",
    "# df_oracle_query = ler_oracle_table(query=query_customizada)\n",
    "# df_oracle_query.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo 3: Leitura com particionamento paralelo (para tabelas grandes)\n",
    "print(\"Exemplo 3: Leitura com particionamento\")\n",
    "# df_oracle_partitioned = ler_oracle_table(\n",
    "#     table_name=ORACLE_TABLE,\n",
    "#     schema=ORACLE_SCHEMA,\n",
    "#     partition_column=\"id\",  # Coluna numérica para particionamento\n",
    "#     num_partitions=10,\n",
    "#     lower_bound=1,\n",
    "#     upper_bound=1000000\n",
    "# )\n",
    "# df_oracle_partitioned.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicionar metadados de ingestão\n",
    "df_ingestao = df_oracle \\\n",
    "    .withColumn(\"fonte\", lit(\"ORACLE\")) \\\n",
    "    .withColumn(\"schema_origem\", lit(ORACLE_SCHEMA)) \\\n",
    "    .withColumn(\"tabela_origem\", lit(ORACLE_TABLE)) \\\n",
    "    .withColumn(\"ingestao_em\", current_timestamp()) \\\n",
    "    .withColumn(\"particao_data\", date_format(current_date(), \"yyyy-MM-dd\"))\n",
    "\n",
    "print(\"Metadados adicionados:\")\n",
    "df_ingestao.select(\"fonte\", \"schema_origem\", \"tabela_origem\", \"ingestao_em\").show(1, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar no MinIO como Delta Table\n",
    "print(f\"Salvando dados em: {DESTINO_BRONZE}\")\n",
    "\n",
    "# save_delta_table(\n",
    "#     df_ingestao,\n",
    "#     DESTINO_BRONZE,\n",
    "#     mode=\"overwrite\",  # ou \"append\" para incrementais\n",
    "#     partition_by=[\"particao_data\"]  # Particionar por data\n",
    "# )\n",
    "\n",
    "print(\"Ingestão concluída com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar dados salvos\n",
    "# df_verificacao = read_delta_table(DESTINO_BRONZE)\n",
    "# print(f\"Registros salvos: {df_verificacao.count()}\")\n",
    "# df_verificacao.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingestão Incremental\n",
    "\n",
    "Para ingestões incrementais baseadas em timestamp ou ID:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para ingestão incremental\n",
    "def ingestao_incremental_oracle(table_name, schema, coluna_timestamp=\"data_atualizacao\", ultima_execucao=None):\n",
    "    \"\"\"\n",
    "    Realiza ingestão incremental de dados Oracle\n",
    "    \n",
    "    Args:\n",
    "        table_name: Nome da tabela\n",
    "        schema: Schema\n",
    "        coluna_timestamp: Nome da coluna de timestamp para filtro\n",
    "        ultima_execucao: Timestamp da última execução (formato Oracle: 'YYYY-MM-DD HH24:MI:SS')\n",
    "    \"\"\"\n",
    "    if ultima_execucao:\n",
    "        query = f\"\"\"\n",
    "            SELECT * FROM {schema}.{table_name}\n",
    "            WHERE {coluna_timestamp} > TO_TIMESTAMP('{ultima_execucao}', 'YYYY-MM-DD HH24:MI:SS')\n",
    "            ORDER BY {coluna_timestamp}\n",
    "        \"\"\"\n",
    "    else:\n",
    "        # Primeira execução: pegar últimos 7 dias\n",
    "        query = f\"\"\"\n",
    "            SELECT * FROM {schema}.{table_name}\n",
    "            WHERE {coluna_timestamp} >= SYSDATE - 7\n",
    "            ORDER BY {coluna_timestamp}\n",
    "        \"\"\"\n",
    "    \n",
    "    df_incremental = ler_oracle_table(query=query)\n",
    "    \n",
    "    return df_incremental\n",
    "\n",
    "# Exemplo de uso\n",
    "# df_incremental = ingestao_incremental_oracle(\n",
    "#     table_name=ORACLE_TABLE,\n",
    "#     schema=ORACLE_SCHEMA,\n",
    "#     ultima_execucao=\"2024-01-01 00:00:00\"\n",
    "# )\n",
    "# \n",
    "# # Salvar em modo append\n",
    "# save_delta_table(df_incremental, DESTINO_BRONZE, mode=\"append\", partition_by=[\"particao_data\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
