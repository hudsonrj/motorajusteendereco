{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregar Dados de Exemplo\n",
    "\n",
    "Este notebook carrega os dados de exemplo CSV para o MinIO (camada Bronze) para testes do motor de correspondência."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar configurações\n",
    "%run ./00_configuracao_inicial.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "import os\n",
    "\n",
    "# Caminho local dos arquivos CSV\n",
    "PATH_DADOS_LOCAL = \"./dados-exemplo/bronze\"\n",
    "\n",
    "# Lista de arquivos para carregar\n",
    "arquivos_csv = {\n",
    "    \"enderecos_livres\": \"enderecos_livres.csv\",\n",
    "    \"enderecos_com_erros\": \"enderecos_com_erros.csv\",\n",
    "    \"dne\": \"dne.csv\",\n",
    "    \"cnefe\": \"cnefe.csv\",\n",
    "    \"osm\": \"osm.csv\",\n",
    "    \"dados_geograficos\": \"dados_geograficos.csv\",\n",
    "    \"variacoes_enderecos\": \"variacoes_enderecos.csv\"\n",
    "}\n",
    "\n",
    "print(\"Arquivos CSV para carregar:\")\n",
    "for nome, arquivo in arquivos_csv.items():\n",
    "    print(f\"  {nome}: {arquivo}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para carregar CSV e salvar no MinIO\n",
    "def carregar_csv_para_minio(nome_tabela, arquivo_csv, destino_path):\n",
    "    \"\"\"\n",
    "    Carrega um arquivo CSV local e salva no MinIO como Delta Table\n",
    "    \n",
    "    Args:\n",
    "        nome_tabela: Nome da tabela\n",
    "        arquivo_csv: Nome do arquivo CSV\n",
    "        destino_path: Caminho de destino no MinIO\n",
    "    \"\"\"\n",
    "    caminho_local = f\"{PATH_DADOS_LOCAL}/{arquivo_csv}\"\n",
    "    \n",
    "    print(f\"\\nCarregando {nome_tabela}...\")\n",
    "    print(f\"  Arquivo: {caminho_local}\")\n",
    "    \n",
    "    # Verificar se arquivo existe\n",
    "    if not os.path.exists(caminho_local):\n",
    "        print(f\"  ERRO: Arquivo não encontrado: {caminho_local}\")\n",
    "        return None\n",
    "    \n",
    "    # Ler CSV\n",
    "    df = spark.read.csv(\n",
    "        caminho_local,\n",
    "        header=True,\n",
    "        inferSchema=True,\n",
    "        encoding=\"utf-8\"\n",
    "    )\n",
    "    \n",
    "    print(f\"  Registros carregados: {df.count()}\")\n",
    "    \n",
    "    # Adicionar metadados\n",
    "    df_com_metadados = df \\\n",
    "        .withColumn(\"carregado_em\", current_timestamp()) \\\n",
    "        .withColumn(\"fonte_dados\", lit(\"EXEMPLO\"))\n",
    "    \n",
    "    # Salvar no MinIO\n",
    "    print(f\"  Salvando em: {destino_path}\")\n",
    "    save_delta_table(\n",
    "        df_com_metadados,\n",
    "        destino_path,\n",
    "        mode=\"overwrite\"\n",
    "    )\n",
    "    \n",
    "    print(f\"  ✓ {nome_tabela} carregado com sucesso!\")\n",
    "    \n",
    "    return df_com_metadados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar endereços livres\n",
    "df_enderecos_livres = carregar_csv_para_minio(\n",
    "    \"enderecos_livres\",\n",
    "    arquivos_csv[\"enderecos_livres\"],\n",
    "    PATH_ENDERECOS_LIVRES\n",
    ")\n",
    "\n",
    "if df_enderecos_livres:\n",
    "    df_enderecos_livres.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar endereços com erros\n",
    "df_enderecos_erros = carregar_csv_para_minio(\n",
    "    \"enderecos_com_erros\",\n",
    "    arquivos_csv[\"enderecos_com_erros\"],\n",
    "    f\"{PATH_BRONZE}/enderecos_com_erros\"\n",
    ")\n",
    "\n",
    "if df_enderecos_erros:\n",
    "    df_enderecos_erros.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar DNE\n",
    "df_dne = carregar_csv_para_minio(\n",
    "    \"dne\",\n",
    "    arquivos_csv[\"dne\"],\n",
    "    PATH_DNE\n",
    ")\n",
    "\n",
    "if df_dne:\n",
    "    df_dne.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar CNEFE\n",
    "df_cnefe = carregar_csv_para_minio(\n",
    "    \"cnefe\",\n",
    "    arquivos_csv[\"cnefe\"],\n",
    "    PATH_CNEFE\n",
    ")\n",
    "\n",
    "if df_cnefe:\n",
    "    df_cnefe.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar OSM\n",
    "df_osm = carregar_csv_para_minio(\n",
    "    \"osm\",\n",
    "    arquivos_csv[\"osm\"],\n",
    "    PATH_OSM\n",
    ")\n",
    "\n",
    "if df_osm:\n",
    "    df_osm.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar dados geográficos\n",
    "df_geograficos = carregar_csv_para_minio(\n",
    "    \"dados_geograficos\",\n",
    "    arquivos_csv[\"dados_geograficos\"],\n",
    "    f\"{PATH_BRONZE}/dados_geograficos\"\n",
    ")\n",
    "\n",
    "if df_geograficos:\n",
    "    df_geograficos.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar variações de endereços\n",
    "df_variacoes = carregar_csv_para_minio(\n",
    "    \"variacoes_enderecos\",\n",
    "    arquivos_csv[\"variacoes_enderecos\"],\n",
    "    f\"{PATH_BRONZE}/variacoes_enderecos\"\n",
    ")\n",
    "\n",
    "if df_variacoes:\n",
    "    df_variacoes.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumo de dados carregados\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RESUMO DE DADOS CARREGADOS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "tabelas = [\n",
    "    (\"Endereços Livres\", PATH_ENDERECOS_LIVRES),\n",
    "    (\"Endereços com Erros\", f\"{PATH_BRONZE}/enderecos_com_erros\"),\n",
    "    (\"DNE\", PATH_DNE),\n",
    "    (\"CNEFE\", PATH_CNEFE),\n",
    "    (\"OSM\", PATH_OSM),\n",
    "    (\"Dados Geográficos\", f\"{PATH_BRONZE}/dados_geograficos\"),\n",
    "    (\"Variações\", f\"{PATH_BRONZE}/variacoes_enderecos\")\n",
    "]\n",
    "\n",
    "for nome, caminho in tabelas:\n",
    "    try:\n",
    "        df = read_delta_table(caminho)\n",
    "        count = df.count()\n",
    "        print(f\"{nome:30} {count:>10} registros\")\n",
    "    except Exception as e:\n",
    "        print(f\"{nome:30} {'ERRO':>10} - {str(e)[:50]}\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"\\nDados de exemplo carregados com sucesso!\")\n",
    "print(\"\\nPróximos passos:\")\n",
    "print(\"  1. Executar notebook 01_tratamento_inicial_ner.ipynb\")\n",
    "print(\"  2. Executar notebook 02_normalizacao_camada_prata.ipynb\")\n",
    "print(\"  3. Executar notebook 03_camada_ouro_deduplicacao.ipynb\")\n",
    "print(\"  4. Executar notebook 05_motor_correspondencia.ipynb\")\n",
    "print(\"  5. Executar notebook 06_validacao_geografica.ipynb\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
